{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNz/3gaXaimnfySgpzNJKbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicoleo/FL_DIAG/blob/main/colab_augmented_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSox-2fISKG",
        "outputId": "5eeb3124-da80-4ade-f865-0680572d3abf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/federicoleo/FL_DIAG.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaKYL5JA8syK",
        "outputId": "9cabec82-bff1-4781-9ace-fd64d38647b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FL_DIAG'...\n",
            "remote: Enumerating objects: 6660, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6660 (delta 0), reused 2 (delta 0), pack-reused 6656 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6660/6660), 813.20 MiB | 42.98 MiB/s, done.\n",
            "Resolving deltas: 100% (2199/2199), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd FL_DIAG\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCgkX3Xb9Ow7",
        "outputId": "fc4413e2-ae0c-46fb-b9a9-e827f9504f0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FL_DIAG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall torch torchvision torchaudio -y\n",
        "# !pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "1CDnMVboD4YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nvjitlink-cu12 -y"
      ],
      "metadata": {
        "id": "P81piMTDGH14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "Ea0DeTM9Elt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFjxo05uEhOc",
        "outputId": "1e4994ac-4c05-499c-f8ee-b14c455117fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6dXCoNJA-Iu7",
        "outputId": "f76413de-32cb-4878-ddc9-9a5064803f0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.3 which is incompatible.\n",
            "pydantic 2.10.6 requires typing-extensions>=4.12.2, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.23.4 which is incompatible.\n",
            "openai 1.61.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPvriExvI_UL",
        "outputId": "e829368e-00dc-40c0-f30b-b31e594e9553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "pygobject 3.42.1 requires pycairo, which is not installed.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\n",
            "torch 2.5.1+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\n",
            "torch 2.5.1+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\n",
            "langchain 0.3.18 has requirement numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.3.\n",
            "pydantic 2.10.6 has requirement typing-extensions>=4.12.2, but you have typing-extensions 4.10.0.\n",
            "pytensor 2.27.1 has requirement filelock>=3.15, but you have filelock 3.13.1.\n",
            "peft 0.14.0 has requirement huggingface-hub>=0.25.0, but you have huggingface-hub 0.23.4.\n",
            "openai 1.61.1 has requirement typing-extensions<5,>=4.11, but you have typing-extensions 4.10.0.\n",
            "gcsfs 2024.10.0 has requirement fsspec==2024.10.0, but you have fsspec 2024.2.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrade typing-extensions so that it meets the requirements of altair, typeguard, pydantic, and openai.\n",
        "!pip install --upgrade \"typing-extensions>=4.12.2,<5\"\n",
        "\n",
        "# Upgrade huggingface-hub to meet peft requirements.\n",
        "!pip install --upgrade \"huggingface-hub>=0.25.0\"\n",
        "\n",
        "# Upgrade fsspec to the version required by gcsfs.\n",
        "!pip install --upgrade \"fsspec==2024.10.0\"\n",
        "\n",
        "# Upgrade filelock to satisfy pytensor.\n",
        "!pip install --upgrade \"filelock>=3.15\"\n",
        "\n",
        "# Upgrade sympy to match torch’s requirement.\n",
        "!pip install --upgrade \"sympy==1.13.1\"\n",
        "\n",
        "# Upgrade triton to the version required by torch.\n",
        "!pip install --upgrade \"triton==3.1.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlm6z7d1VjUm",
        "outputId": "f698ed4a-c881-4c2a-f1c7-8d1d17917c80"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions<5,>=4.12.2\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.12.2\n",
            "Collecting huggingface-hub>=0.25.0\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (2024.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0) (2024.6.2)\n",
            "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.23.4\n",
            "    Uninstalling huggingface-hub-0.23.4:\n",
            "      Successfully uninstalled huggingface-hub-0.23.4\n",
            "Successfully installed huggingface-hub-0.29.1\n",
            "Collecting fsspec==2024.10.0\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.10.0\n",
            "Collecting filelock>=3.15\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: filelock\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filelock-3.17.0\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1) (1.3.0)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==3.1.0) (3.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcy6n6lkWnjG",
        "outputId": "018557a7-114a-4cdb-8625-4ea52b4924e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "pygobject 3.42.1 requires pycairo, which is not installed.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61.\n",
            "torch 2.5.1+cu124 has requirement nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83.\n",
            "torch 2.5.1+cu124 has requirement nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3.\n",
            "torch 2.5.1+cu124 has requirement nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82.\n",
            "langchain 0.3.18 has requirement numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpsBlyrbYy9",
        "outputId": "3d48c93f-8863-4367-ebc0-7af90e6a4a4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.41.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.49.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgVwffCCZJIe",
        "outputId": "03004d2c-0b46-4511-d067-d17e6092bf17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.49.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ksdd2_downloader.py --out_path data/ksdd2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3izlGdIWLBe",
        "outputId": "e9bbef72-57b2-481b-839f-1f6117bf0d0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading KolektorSDD2 dataset...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ksdd2_preprocess.py --src_dir=\"data/ksdd2\" --dst_dir=\"data/ksdd2_preprocessed\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtFN8n_qXbfa",
        "outputId": "201e1b57-ea78-42ed-885a-8bad504759e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying files from data/ksdd2 to data/ksdd2_preprocessed\n",
            "Copying .pyb files: 100% 5/5 [00:00<00:00, 165.07file/s]\n",
            "Reshaping train images: 100% 4664/4664 [00:36<00:00, 126.35file/s]\n",
            "Reshaping test images: 100% 2008/2008 [00:16<00:00, 122.60file/s]\n",
            "Creating train.csv: 100% 2332/2332 [00:55<00:00, 41.88file/s]\n",
            "Creating test.csv: 100% 1004/1004 [00:24<00:00, 41.65file/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_augmented_images.py --src_dir=\"data/ksdd2_preprocessed\" --imgs_per_prompt=10  --seed=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-pCScZ3YT5R",
        "outputId": "44e2f29b-b4fa-444c-f772-647a982b6354"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-20 15:58:57.369622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740067137.391030    6353 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740067137.397286    6353 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
            "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
            "Running on device:  cuda\n",
            "Num negative images: 2085\n",
            "Num positive masks: 247\n",
            "Loading model diffusers/stable-diffusion-xl-1.0-inpainting-0.1\n",
            "model_index.json: 100% 690/690 [00:00<00:00, 3.95MB/s]\n",
            "Fetching 18 files:   0% 0/18 [00:00<?, ?it/s]\n",
            "scheduler%2Fscheduler_config.json: 100% 479/479 [00:00<00:00, 3.24MB/s]\n",
            "Fetching 18 files:  11% 2/18 [00:00<00:01, 10.52it/s]\n",
            "text_encoder_2%2Fconfig.json: 100% 758/758 [00:00<00:00, 6.14MB/s]\n",
            "\n",
            "text_encoder%2Fconfig.json: 100% 746/746 [00:00<00:00, 7.61MB/s]\n",
            "\n",
            "model.fp16.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer%2Ftokenizer_config.json: 100% 737/737 [00:00<00:00, 5.00MB/s]\n",
            "\n",
            "\n",
            "tokenizer%2Fspecial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.22MB/s]\n",
            "\n",
            "\n",
            "tokenizer%2Fmerges.txt: 100% 525k/525k [00:00<00:00, 6.56MB/s]\n",
            "\n",
            "\n",
            "tokenizer%2Fvocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_2%2Fspecial_tokens_map.json: 100% 460/460 [00:00<00:00, 4.81MB/s]\n",
            "\n",
            "model.fp16.safetensors:   4% 10.5M/246M [00:00<00:04, 49.6MB/s]\u001b[A\n",
            "\n",
            "tokenizer%2Fvocab.json: 100% 1.06M/1.06M [00:00<00:00, 7.25MB/s]\n",
            "\n",
            "\n",
            "unet%2Fconfig.json: 100% 1.93k/1.93k [00:00<00:00, 14.7MB/s]\n",
            "\n",
            "model.fp16.safetensors:   9% 21.0M/246M [00:00<00:03, 64.0MB/s]\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   0% 0.00/5.14G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2%2Ftokenizer_config.json: 100% 725/725 [00:00<00:00, 5.43MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "vae%2Fconfig.json: 100% 659/659 [00:00<00:00, 6.79MB/s]\n",
            "\n",
            "model.fp16.safetensors:  13% 31.5M/246M [00:00<00:02, 73.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   0% 10.5M/5.14G [00:00<00:55, 92.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   1% 10.5M/1.39G [00:00<00:30, 44.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   1% 31.5M/5.14G [00:00<00:39, 128MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  21% 52.4M/246M [00:00<00:02, 92.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   6% 10.5M/167M [00:00<00:03, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   2% 21.0M/1.39G [00:00<00:25, 53.2MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  26% 62.9M/246M [00:00<00:02, 86.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   1% 52.4M/5.14G [00:00<00:43, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  13% 21.0M/167M [00:00<00:02, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   2% 31.5M/1.39G [00:00<00:23, 59.0MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  30% 73.4M/246M [00:00<00:02, 80.4MB/s]\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   3% 41.9M/1.39G [00:00<00:21, 61.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  25% 41.9M/167M [00:00<00:01, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   1% 73.4M/5.14G [00:00<00:54, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  38% 94.4M/246M [00:01<00:01, 87.9MB/s]\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   4% 52.4M/1.39G [00:00<00:18, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  31% 52.4M/167M [00:00<00:01, 79.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  43% 105M/246M [00:01<00:01, 84.4MB/s] \u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   2% 94.4M/5.14G [00:00<00:52, 96.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   5% 62.9M/1.39G [00:00<00:17, 74.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   5% 73.4M/1.39G [00:01<00:16, 79.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   2% 105M/5.14G [00:01<00:53, 93.5MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  47% 115M/246M [00:01<00:01, 80.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  44% 73.4M/167M [00:00<00:01, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   6% 83.9M/1.39G [00:01<00:15, 83.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  50% 83.9M/167M [00:01<00:00, 87.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  51% 126M/246M [00:01<00:01, 80.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   2% 115M/5.14G [00:01<00:58, 86.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   7% 94.4M/1.39G [00:01<00:14, 87.1MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  55% 136M/246M [00:01<00:01, 77.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   2% 126M/5.14G [00:01<01:02, 80.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   8% 105M/1.39G [00:01<00:14, 88.1MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  63% 105M/167M [00:01<00:00, 91.9MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  64% 157M/246M [00:02<00:01, 71.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  69% 115M/167M [00:01<00:00, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   3% 147M/5.14G [00:01<01:10, 71.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   8% 115M/1.39G [00:01<00:22, 56.2MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  68% 168M/246M [00:02<00:01, 73.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  75% 126M/167M [00:01<00:00, 65.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   3% 157M/5.14G [00:01<01:11, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:   9% 126M/1.39G [00:01<00:21, 59.1MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  72% 178M/246M [00:02<00:00, 69.1MB/s]\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  10% 136M/1.39G [00:02<00:18, 67.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  81% 136M/167M [00:01<00:00, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   3% 168M/5.14G [00:02<01:12, 68.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  77% 189M/246M [00:02<00:00, 71.8MB/s]\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  11% 147M/1.39G [00:02<00:17, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  94% 157M/167M [00:02<00:00, 85.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  81% 199M/246M [00:02<00:00, 77.4MB/s]\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100% 167M/167M [00:02<00:00, 74.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   4% 189M/5.14G [00:02<01:21, 60.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  12% 168M/1.39G [00:02<00:17, 68.0MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  89% 220M/246M [00:02<00:00, 75.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   4% 199M/5.14G [00:02<01:16, 64.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  14% 189M/1.39G [00:02<00:16, 75.0MB/s]\u001b[A\u001b[A\n",
            "model.fp16.safetensors:  98% 241M/246M [00:03<00:00, 80.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   4% 210M/5.14G [00:02<01:19, 62.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  14% 199M/1.39G [00:04<01:11, 16.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.fp16.safetensors: 100% 246M/246M [00:05<00:00, 47.2MB/s]\n",
            "Fetching 18 files:  22% 4/18 [00:05<00:22,  1.59s/it]\n",
            "\n",
            "model.fp16.safetensors:  16% 220M/1.39G [00:04<00:44, 26.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   5% 241M/5.14G [00:05<03:13, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  17% 241M/1.39G [00:05<00:30, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   5% 262M/5.14G [00:05<02:10, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   6% 283M/5.14G [00:05<01:39, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  19% 262M/1.39G [00:05<00:23, 47.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  20% 273M/1.39G [00:05<00:21, 52.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   6% 304M/5.14G [00:05<01:20, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  21% 294M/1.39G [00:05<00:15, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   6% 325M/5.14G [00:05<01:05, 73.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  23% 315M/1.39G [00:05<00:13, 79.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   7% 346M/5.14G [00:05<00:56, 85.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  24% 336M/1.39G [00:05<00:11, 89.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   7% 367M/5.14G [00:05<00:50, 94.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  26% 357M/1.39G [00:06<00:10, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   8% 388M/5.14G [00:06<00:46, 101MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  27% 377M/1.39G [00:06<00:08, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   8% 409M/5.14G [00:06<00:44, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  29% 398M/1.39G [00:06<00:08, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   8% 430M/5.14G [00:06<00:40, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  30% 419M/1.39G [00:06<00:07, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   9% 451M/5.14G [00:06<00:37, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  32% 440M/1.39G [00:06<00:07, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:   9% 472M/5.14G [00:06<00:33, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  33% 461M/1.39G [00:06<00:06, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  10% 493M/5.14G [00:06<00:31, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  35% 482M/1.39G [00:06<00:06, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  10% 514M/5.14G [00:06<00:30, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  36% 503M/1.39G [00:07<00:05, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  10% 535M/5.14G [00:07<00:31, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  38% 524M/1.39G [00:07<00:05, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  11% 556M/5.14G [00:07<00:28, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  39% 545M/1.39G [00:07<00:05, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  11% 577M/5.14G [00:07<00:27, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  41% 566M/1.39G [00:07<00:04, 169MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  12% 598M/5.14G [00:07<00:28, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  42% 587M/1.39G [00:07<00:04, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  12% 619M/5.14G [00:07<00:29, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  44% 608M/1.39G [00:07<00:04, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  12% 640M/5.14G [00:07<00:29, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  45% 629M/1.39G [00:07<00:04, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  13% 661M/5.14G [00:07<00:31, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  47% 650M/1.39G [00:08<00:05, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  13% 682M/5.14G [00:08<00:31, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  48% 671M/1.39G [00:08<00:05, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  14% 703M/5.14G [00:08<00:30, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  50% 692M/1.39G [00:08<00:05, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  14% 724M/5.14G [00:08<00:34, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  51% 713M/1.39G [00:08<00:05, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  14% 744M/5.14G [00:08<00:32, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  53% 734M/1.39G [00:08<00:05, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  15% 765M/5.14G [00:08<00:33, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  54% 755M/1.39G [00:08<00:05, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  15% 786M/5.14G [00:08<00:32, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  56% 776M/1.39G [00:11<00:22, 27.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  16% 807M/5.14G [00:11<02:34, 28.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  58% 807M/1.39G [00:11<00:13, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  16% 839M/5.14G [00:11<01:41, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  17% 860M/5.14G [00:11<01:20, 52.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  60% 828M/1.39G [00:11<00:10, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  61% 849M/1.39G [00:11<00:08, 62.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  17% 881M/5.14G [00:11<01:06, 63.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  63% 870M/1.39G [00:11<00:06, 76.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  18% 902M/5.14G [00:11<00:55, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  64% 891M/1.39G [00:13<00:14, 33.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  66% 912M/1.39G [00:13<00:10, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  18% 923M/5.14G [00:13<02:15, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  68% 944M/1.39G [00:14<00:13, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  18% 933M/5.14G [00:14<03:23, 20.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  69% 965M/1.39G [00:14<00:10, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  18% 944M/5.14G [00:14<02:58, 23.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  72% 996M/1.39G [00:14<00:06, 58.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  19% 954M/5.14G [00:14<02:28, 28.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  73% 1.02G/1.39G [00:14<00:05, 71.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  75% 1.04G/1.39G [00:16<00:12, 28.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  19% 975M/5.14G [00:17<04:20, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  76% 1.06G/1.39G [00:17<00:09, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  19% 996M/5.14G [00:17<02:57, 23.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  78% 1.08G/1.39G [00:17<00:07, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  20% 1.02G/5.14G [00:17<02:06, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  20% 1.03G/5.14G [00:17<01:49, 37.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  79% 1.10G/1.39G [00:17<00:05, 52.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  20% 1.05G/5.14G [00:17<01:23, 49.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  81% 1.12G/1.39G [00:17<00:04, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  21% 1.07G/5.14G [00:17<01:04, 62.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  21% 1.09G/5.14G [00:17<00:50, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  82% 1.14G/1.39G [00:18<00:03, 61.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  22% 1.11G/5.14G [00:18<00:42, 94.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  84% 1.16G/1.39G [00:18<00:03, 72.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  22% 1.13G/5.14G [00:18<00:39, 100MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  85% 1.18G/1.39G [00:18<00:02, 80.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  22% 1.15G/5.14G [00:18<00:37, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  87% 1.21G/1.39G [00:18<00:01, 92.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  23% 1.17G/5.14G [00:18<00:35, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  88% 1.23G/1.39G [00:18<00:01, 105MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  23% 1.20G/5.14G [00:18<00:35, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  90% 1.25G/1.39G [00:18<00:01, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  24% 1.22G/5.14G [00:18<00:32, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  91% 1.27G/1.39G [00:19<00:01, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  24% 1.24G/5.14G [00:19<00:30, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  93% 1.29G/1.39G [00:19<00:00, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  25% 1.26G/5.14G [00:19<00:27, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  94% 1.31G/1.39G [00:19<00:00, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  25% 1.28G/5.14G [00:19<00:25, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  96% 1.33G/1.39G [00:19<00:00, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  25% 1.30G/5.14G [00:19<00:25, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  97% 1.35G/1.39G [00:19<00:00, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  26% 1.32G/5.14G [00:19<00:24, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors:  99% 1.37G/1.39G [00:19<00:00, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.fp16.safetensors: 100% 1.39G/1.39G [00:19<00:00, 70.2MB/s]\n",
            "Fetching 18 files:  33% 6/18 [00:20<00:51,  4.27s/it]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  27% 1.36G/5.14G [00:19<00:23, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  27% 1.39G/5.14G [00:19<00:20, 187MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  28% 1.43G/5.14G [00:20<00:18, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  28% 1.46G/5.14G [00:20<00:17, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  29% 1.49G/5.14G [00:20<00:16, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  30% 1.52G/5.14G [00:20<00:15, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  30% 1.55G/5.14G [00:20<00:15, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  31% 1.58G/5.14G [00:20<00:15, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  31% 1.61G/5.14G [00:20<00:14, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  32% 1.65G/5.14G [00:21<00:14, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  33% 1.68G/5.14G [00:21<00:15, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  33% 1.71G/5.14G [00:21<00:15, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  34% 1.74G/5.14G [00:21<00:15, 225MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  35% 1.77G/5.14G [00:21<00:15, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  35% 1.80G/5.14G [00:21<00:15, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  36% 1.84G/5.14G [00:21<00:14, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  36% 1.87G/5.14G [00:22<00:14, 231MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  37% 1.90G/5.14G [00:22<00:14, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  38% 1.93G/5.14G [00:22<00:14, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  38% 1.96G/5.14G [00:22<00:13, 235MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  39% 1.99G/5.14G [00:22<00:12, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  39% 2.02G/5.14G [00:22<00:12, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  40% 2.06G/5.14G [00:22<00:12, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  41% 2.09G/5.14G [00:22<00:12, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  41% 2.12G/5.14G [00:23<00:13, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  42% 2.15G/5.14G [00:23<00:19, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  42% 2.18G/5.14G [00:23<00:17, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  43% 2.21G/5.14G [00:23<00:15, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  44% 2.24G/5.14G [00:23<00:14, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  44% 2.28G/5.14G [00:24<00:14, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  45% 2.31G/5.14G [00:24<00:13, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  46% 2.34G/5.14G [00:24<00:13, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  46% 2.37G/5.14G [00:24<00:24, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  47% 2.40G/5.14G [00:24<00:20, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  47% 2.43G/5.14G [00:25<00:17, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  48% 2.46G/5.14G [00:25<00:16, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  48% 2.49G/5.14G [00:25<00:16, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  49% 2.51G/5.14G [00:25<00:16, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  49% 2.53G/5.14G [00:25<00:16, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  50% 2.56G/5.14G [00:25<00:14, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  50% 2.58G/5.14G [00:26<00:43, 58.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  51% 2.61G/5.14G [00:27<00:31, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  51% 2.64G/5.14G [00:27<00:24, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  52% 2.67G/5.14G [00:27<00:19, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  53% 2.71G/5.14G [00:27<00:16, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  53% 2.74G/5.14G [00:27<00:14, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  54% 2.77G/5.14G [00:27<00:12, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  55% 2.80G/5.14G [00:27<00:12, 194MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  55% 2.83G/5.14G [00:27<00:11, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  56% 2.86G/5.14G [00:28<00:10, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  56% 2.89G/5.14G [00:28<00:10, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  57% 2.93G/5.14G [00:28<00:10, 214MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  58% 2.96G/5.14G [00:28<00:10, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  58% 2.99G/5.14G [00:28<00:09, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  59% 3.02G/5.14G [00:28<00:09, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  59% 3.05G/5.14G [00:28<00:09, 224MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  60% 3.08G/5.14G [00:29<00:09, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  61% 3.11G/5.14G [00:29<00:09, 213MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  61% 3.15G/5.14G [00:29<00:09, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  62% 3.17G/5.14G [00:29<00:09, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  62% 3.19G/5.14G [00:29<00:09, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  62% 3.21G/5.14G [00:29<00:09, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  63% 3.24G/5.14G [00:29<00:09, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  64% 3.27G/5.14G [00:30<00:08, 213MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  64% 3.30G/5.14G [00:30<00:08, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  65% 3.33G/5.14G [00:30<00:08, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  66% 3.37G/5.14G [00:30<00:08, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  66% 3.39G/5.14G [00:30<00:08, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  66% 3.41G/5.14G [00:30<00:08, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  67% 3.44G/5.14G [00:30<00:08, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  67% 3.46G/5.14G [00:31<00:08, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  68% 3.49G/5.14G [00:31<00:07, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  69% 3.52G/5.14G [00:31<00:07, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  69% 3.55G/5.14G [00:31<00:06, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  70% 3.59G/5.14G [00:31<00:07, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  70% 3.62G/5.14G [00:31<00:07, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  71% 3.65G/5.14G [00:31<00:06, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  72% 3.68G/5.14G [00:31<00:06, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  72% 3.71G/5.14G [00:32<00:06, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  73% 3.74G/5.14G [00:32<00:06, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  74% 3.77G/5.14G [00:32<00:06, 223MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  74% 3.81G/5.14G [00:32<00:06, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  75% 3.84G/5.14G [00:32<00:05, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  75% 3.87G/5.14G [00:32<00:05, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  76% 3.90G/5.14G [00:32<00:05, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  77% 3.93G/5.14G [00:33<00:04, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  77% 3.96G/5.14G [00:33<00:04, 235MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  78% 4.00G/5.14G [00:33<00:04, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  78% 4.03G/5.14G [00:33<00:04, 235MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  79% 4.06G/5.14G [00:33<00:04, 229MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  80% 4.09G/5.14G [00:33<00:04, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  80% 4.12G/5.14G [00:33<00:04, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  81% 4.15G/5.14G [00:34<00:04, 230MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  81% 4.18G/5.14G [00:34<00:04, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  82% 4.22G/5.14G [00:34<00:03, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  83% 4.25G/5.14G [00:34<00:03, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  83% 4.28G/5.14G [00:34<00:03, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  84% 4.31G/5.14G [00:34<00:03, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  85% 4.34G/5.14G [00:34<00:03, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  85% 4.37G/5.14G [00:34<00:03, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  86% 4.40G/5.14G [00:35<00:03, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  86% 4.44G/5.14G [00:35<00:02, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  87% 4.47G/5.14G [00:35<00:02, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  88% 4.50G/5.14G [00:35<00:02, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  88% 4.53G/5.14G [00:35<00:02, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  89% 4.56G/5.14G [00:35<00:02, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  89% 4.59G/5.14G [00:35<00:02, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  90% 4.62G/5.14G [00:35<00:02, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  91% 4.66G/5.14G [00:36<00:01, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  91% 4.69G/5.14G [00:36<00:01, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  92% 4.72G/5.14G [00:36<00:01, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  93% 4.75G/5.14G [00:36<00:01, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  93% 4.78G/5.14G [00:36<00:01, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  94% 4.81G/5.14G [00:36<00:01, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  94% 4.84G/5.14G [00:36<00:01, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  95% 4.88G/5.14G [00:37<00:01, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  96% 4.91G/5.14G [00:37<00:00, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  96% 4.94G/5.14G [00:37<00:00, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  97% 4.97G/5.14G [00:37<00:00, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  97% 5.00G/5.14G [00:37<00:00, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  98% 5.03G/5.14G [00:37<00:00, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  99% 5.06G/5.14G [00:37<00:00, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors:  99% 5.10G/5.14G [00:37<00:00, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100% 5.14G/5.14G [00:38<00:00, 135MB/s]\n",
            "Fetching 18 files: 100% 18/18 [00:38<00:00,  2.15s/it]\n",
            "Loading pipeline components...:  57% 4/7 [00:01<00:01,  2.67it/s]The config attributes {'decay': 0.9999, 'inv_gamma': 1.0, 'min_decay': 0.0, 'optimization_step': 37000, 'power': 0.6666666666666666, 'update_after_step': 0, 'use_ema_warmup': False} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "Loading pipeline components...: 100% 7/7 [00:03<00:00,  2.03it/s]\n",
            "Generating images for prompt: white marks on the wall\n",
            "100% 29/29 [00:20<00:00,  1.41it/s]\n",
            "100% 29/29 [00:20<00:00,  1.38it/s]\n",
            "100% 29/29 [00:21<00:00,  1.35it/s]\n",
            "100% 29/29 [00:22<00:00,  1.30it/s]\n",
            "100% 29/29 [00:22<00:00,  1.30it/s]\n",
            "100% 29/29 [00:21<00:00,  1.33it/s]\n",
            "100% 29/29 [00:21<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.31it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "Generating images for prompt: copper metal scratches\n",
            "100% 29/29 [00:21<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.31it/s]\n",
            "100% 29/29 [00:22<00:00,  1.31it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n",
            "100% 29/29 [00:22<00:00,  1.32it/s]\n"
          ]
        }
      ]
    }
  ]
}